#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç CSV —Ñ–∞–π–ª —Å–æ —Å–ø–ª–∏—Ç–æ–º train/validation –Ω–∞ –æ—Å–Ω–æ–≤–µ IDs –∏–∑ –∫—ç—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
"""

import argparse
from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split


def generate_split_from_embeddings(
        embeddings_path: Path,
        output_path: Path,
        val_size: float = 0.2,
        random_seed: int = 42,
) -> None:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç split —Ñ–∞–π–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ model_ids –∏–∑ –∫—ç—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.

    Args:
        embeddings_path: –ü—É—Ç—å –∫ .npz —Ñ–∞–π–ª—É —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV —Ñ–∞–π–ª–∞
        val_size: –î–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ (0.2 = 20%)
        random_seed: Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    """

    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ {embeddings_path}...")
    data = np.load(embeddings_path)
    filenames = data["filenames"]

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ model_ids
    model_ids = set()
    for fname in filenames:
        model_id = fname.split('_')[0]  # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (—Å—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞ "0525")
        model_ids.add(model_id)

    model_ids = sorted(list(model_ids))
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(model_ids)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ CSV (load_split_ids_from_csv –æ–∂–∏–¥–∞–µ—Ç —á–∏—Å–ª–∞)
    model_ids_numeric = [int(mid) for mid in model_ids]

    # –î–µ–ª–∏–º –Ω–∞ train/val
    train_ids, val_ids = train_test_split(
        model_ids_numeric,
        test_size=val_size,
        random_state=random_seed,
        shuffle=True
    )

    print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   ‚Ä¢ Train: {len(train_ids)} –º–æ–¥–µ–ª–µ–π ({len(train_ids) / len(model_ids_numeric) * 100:.1f}%)")
    print(f"   ‚Ä¢ Val: {len(val_ids)} –º–æ–¥–µ–ª–µ–π ({len(val_ids) / len(model_ids_numeric) * 100:.1f}%)")

    # –°–æ–∑–¥–∞–µ–º DataFrame
    train_df = pd.DataFrame({
        'model_id': train_ids,
        'split': 'train'
    })

    val_df = pd.DataFrame({
        'model_id': val_ids,
        'split': 'validation'
    })

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    df = pd.concat([train_df, val_df], ignore_index=True)
    df = df.sort_values('model_id').reset_index(drop=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_path.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(output_path, index=False)

    print(f"\n‚úÖ Split —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_path}")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –∏–∑ —Ñ–∞–π–ª–∞:")
    print(df.head(10))

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(df['split'].value_counts())


def main():
    parser = argparse.ArgumentParser(
        description="–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç train/validation split –∏–∑ –∫—ç—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
    )
    parser.add_argument(
        "--embeddings",
        type=Path,
        default="embeddings/train_img_embeddings_stage1.npz",
        help="–ü—É—Ç—å –∫ .npz —Ñ–∞–π–ª—É —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"
    )
    parser.add_argument(
        "--output",
        type=Path,
        default="splits/base_split.csv",
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV —Ñ–∞–π–ª–∞ —Å–æ —Å–ø–ª–∏—Ç–æ–º"
    )
    parser.add_argument(
        "--val-size",
        type=float,
        default=0.2,
        help="–î–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ (default: 0.2)"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ (default: 42)"
    )

    args = parser.parse_args()

    if not args.embeddings.exists():
        print(f"‚ùå –§–∞–π–ª —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.embeddings}")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ extract_train_embeddings.py")
        exit(1)

    generate_split_from_embeddings(
        embeddings_path=args.embeddings,
        output_path=args.output,
        val_size=args.val_size,
        random_seed=args.seed,
    )


if __name__ == "__main__":
    main()