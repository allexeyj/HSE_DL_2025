import json
import random
from functools import partial
from pathlib import Path

import numpy as np
import pandas as pd
import torch
from easydict import EasyDict as edict
from torch.utils.data import DataLoader

from .datasets import TextMeshDataset, train_collate_fn
from .type_defs import ModelID, PathLike


def worker_init_fn(worker_id: int, base_seed: int) -> None:
    worker_seed = base_seed + worker_id
    np.random.seed(worker_seed)
    random.seed(worker_seed)
    torch.manual_seed(worker_seed)


def load_split_ids_from_csv(filepath: PathLike) -> tuple[list[ModelID], list[ModelID]]:
    if not Path(filepath).exists():
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")

    # –í–ê–ñ–ù–û: —á–∏—Ç–∞–µ–º model_id –∫–∞–∫ —Å—Ç—Ä–æ–∫—É, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–µ–¥—É—â–∏–µ –Ω—É–ª–∏
    df = pd.read_csv(filepath, dtype={'model_id': str})

    # –ï—Å–ª–∏ –≤ CSV –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
    if 'model_id' not in df.columns and 'split' not in df.columns:
        df.columns = ['model_id', 'split']

    train_ids = df[df["split"] == "train"]["model_id"].tolist()
    val_ids = df[df["split"] == "validation"]["model_id"].tolist()

    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ split —Ñ–∞–π–ª–∞:")
    print(f"   Train IDs: {len(train_ids)} (–ø—Ä–∏–º–µ—Ä—ã: {train_ids[:3]})")
    print(f"   Val IDs: {len(val_ids)} (–ø—Ä–∏–º–µ—Ä—ã: {val_ids[:3]})")

    return train_ids, val_ids


def get_loaders(config: edict) -> tuple[DataLoader, DataLoader]:
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ split —Ñ–∞–π–ª–∞
    split_path = Path(config.paths.split_filepath)
    if not split_path.exists():
        raise FileNotFoundError(f"Split —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {split_path}")

    train_ids, val_ids = load_split_ids_from_csv(config.paths.split_filepath)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ ID –Ω–µ –ø—É—Å—Ç—ã–µ
    assert len(train_ids) > 0, f"Train IDs –ø—É—Å—Ç—ã–µ!"
    assert len(val_ids) > 0, f"Val IDs –ø—É—Å—Ç—ã–µ!"

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å captions
    with open(config.paths.captions_file, 'r') as f:
        captions = json.load(f)

    train_ids_found = [tid for tid in train_ids if tid in captions]
    val_ids_found = [vid for vid in val_ids if vid in captions]

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –≤ captions:")
    print(f"   Train: {len(train_ids_found)}/{len(train_ids)}")
    print(f"   Val: {len(val_ids_found)}/{len(val_ids)}")

    if len(train_ids_found) == 0:
        print("‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º ID!")
        print(f"   –ü—Ä–∏–º–µ—Ä—ã train IDs –∏–∑ split: {train_ids[:5]}")
        print(f"   –ü—Ä–∏–º–µ—Ä—ã –∫–ª—é—á–µ–π –∏–∑ captions: {list(captions.keys())[:5]}")
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –º–µ–∂–¥—É split –∏ captions")

    init_fn = partial(worker_init_fn, base_seed=config.seed)

    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ ID
    train_ds = TextMeshDataset(
        config.paths.train_data_root,
        config.paths.captions_file,
        npoints=config.npoints,
        model_ids=train_ids,
        pc_augment=True,
        base_seed=config.seed,
    )

    val_ds = TextMeshDataset(
        config.paths.train_data_root,
        config.paths.captions_file,
        npoints=config.npoints,
        model_ids=val_ids,
        pc_augment=False,
        base_seed=config.seed,
    )

    train_loader = DataLoader(
        train_ds,
        batch_size=config.train_params.batch_size,
        shuffle=True,
        num_workers=config.train_params.num_workers,
        collate_fn=train_collate_fn,
        drop_last=True,
        worker_init_fn=init_fn,
    )

    val_loader = DataLoader(
        val_ds,
        batch_size=config.train_params.batch_size,
        shuffle=False,
        num_workers=config.train_params.num_workers,
        collate_fn=train_collate_fn,
        worker_init_fn=init_fn,
    )

    print("\n‚úÖ DataLoader'—ã —Å–æ–∑–¥–∞–Ω—ã:")
    print(f"  Train: {len(train_ds)} samples")
    print(f"  Val: {len(val_ds)} samples")

    return train_loader, val_loader